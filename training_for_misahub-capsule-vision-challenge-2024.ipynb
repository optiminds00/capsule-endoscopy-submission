{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Installing and importing libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-23T10:56:27.943574Z","iopub.status.busy":"2024-10-23T10:56:27.942937Z","iopub.status.idle":"2024-10-23T10:56:52.757117Z","shell.execute_reply":"2024-10-23T10:56:52.756038Z","shell.execute_reply.started":"2024-10-23T10:56:27.943540Z"},"trusted":true},"outputs":[],"source":["!pip install evaluate\n","!pip install accelerate"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T10:57:04.744629Z","iopub.status.busy":"2024-10-23T10:57:04.744243Z","iopub.status.idle":"2024-10-23T10:57:23.963087Z","shell.execute_reply":"2024-10-23T10:57:23.962148Z","shell.execute_reply.started":"2024-10-23T10:57:04.744587Z"},"trusted":true},"outputs":[],"source":["import os\n","import torch\n","import random\n","import evaluate\n","import numpy as np\n","from PIL import ImageOps, ImageFilter\n","from torchvision import datasets, models, transforms\n","from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer\n"]},{"cell_type":"markdown","metadata":{},"source":["## Training on training data and Evaluation on validation data"]},{"cell_type":"markdown","metadata":{},"source":["### model checkpoint"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T10:59:10.986247Z","iopub.status.busy":"2024-10-23T10:59:10.984816Z","iopub.status.idle":"2024-10-23T10:59:10.990090Z","shell.execute_reply":"2024-10-23T10:59:10.989183Z","shell.execute_reply.started":"2024-10-23T10:59:10.986205Z"},"trusted":true},"outputs":[],"source":["checkpoint = \"microsoft/swin-tiny-patch4-window7-224\""]},{"cell_type":"markdown","metadata":{},"source":["### image processor "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T10:59:13.105080Z","iopub.status.busy":"2024-10-23T10:59:13.104372Z","iopub.status.idle":"2024-10-23T10:59:13.561378Z","shell.execute_reply":"2024-10-23T10:59:13.560523Z","shell.execute_reply.started":"2024-10-23T10:59:13.105041Z"},"trusted":true},"outputs":[],"source":["image_processor = AutoImageProcessor.from_pretrained(checkpoint, use_fast=True)"]},{"cell_type":"markdown","metadata":{},"source":["### transforming data for model"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T10:59:18.179838Z","iopub.status.busy":"2024-10-23T10:59:18.179460Z","iopub.status.idle":"2024-10-23T10:59:18.186709Z","shell.execute_reply":"2024-10-23T10:59:18.185789Z","shell.execute_reply.started":"2024-10-23T10:59:18.179801Z"},"trusted":true},"outputs":[],"source":["\n","normalize = transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n","\n","size = (\n","    image_processor.size[\"shortest_edge\"]\n","    if \"shortest_edge\" in image_processor.size\n","    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",")\n","\n","_transforms =  {\n","    'training' :transforms.Compose([transforms.Resize(size), transforms.ToTensor(), normalize]),\n","\n","    'validation' :transforms.Compose([transforms.Resize(size), transforms.ToTensor(), normalize])\n","}"]},{"cell_type":"markdown","metadata":{},"source":["### dataset loading"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T10:59:22.185424Z","iopub.status.busy":"2024-10-23T10:59:22.184362Z","iopub.status.idle":"2024-10-23T10:59:47.578281Z","shell.execute_reply":"2024-10-23T10:59:47.577339Z","shell.execute_reply.started":"2024-10-23T10:59:22.185381Z"},"trusted":true},"outputs":[],"source":["\n","data_dir = \"Dataset\"\n","\n","\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          _transforms[x])\n","                  for x in ['training', 'validation']}\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['training', 'validation']}\n","\n","class_names = image_datasets['validation'].classes\n","\n","print(\"classes ============ \",class_names)\n","\n","label2id, id2label = dict(), dict()\n","\n","for i, label in enumerate(class_names):\n","    label2id[label] = str(i)\n","    id2label[str(i)] = label\n"]},{"cell_type":"markdown","metadata":{},"source":["### sampling 0.08 % of normal class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T10:59:56.420066Z","iopub.status.busy":"2024-10-23T10:59:56.419697Z","iopub.status.idle":"2024-10-23T11:00:05.254884Z","shell.execute_reply":"2024-10-23T11:00:05.254068Z","shell.execute_reply.started":"2024-10-23T10:59:56.420030Z"},"trusted":true},"outputs":[],"source":["\n","# Function to sample the dataset\n","def sample_normal_class(dataset, class_name, sample_fraction=0.1):\n","    # Identify indices of the specified class\n","    class_indices = [i for i, (_, label) in enumerate(dataset.samples) if label == int(label2id[class_name])]\n","    print(f\"Class {class_name} length:\", len(class_indices))  # Should be > 0 if the class exists\n","\n","    # Sample only if there are indices available\n","    if len(class_indices) > 0:\n","        sample_size = int(len(class_indices) * sample_fraction)\n","        sampled_indices = random.sample(class_indices, sample_size)\n","        print(\"Sample length:\", len(sampled_indices))  # Should be > 0\n","    else:\n","        sampled_indices = []  # No samples if class length is 0\n","        print(\"No samples to draw from the specified class.\")\n","\n","    # Get indices for all other classes\n","    other_class_indices = [i for i in range(len(dataset)) if dataset.samples[i][1] != int(label2id[class_name])]\n","\n","    combined_indices = other_class_indices + sampled_indices\n","    return combined_indices\n","\n","# Sample the \"Normal\" class and create a new dataset\n","sampled_training_indices = sample_normal_class(image_datasets['training'], 'Normal', sample_fraction=0.08)\n","sampled_validation_indices = sample_normal_class(image_datasets['validation'], 'Normal', sample_fraction=0.08)\n","\n","\n","# Create a new dataset based on sampled indices\n","class SampledImageFolder(datasets.ImageFolder):\n","    def __init__(self, dataset, indices):\n","        super().__init__(dataset.root, dataset.transform)\n","        self.samples = [dataset.samples[i] for i in indices]\n","        self.targets = [dataset.targets[i] for i in indices]\n","\n","# Instantiate the sampled dataset\n","sampled_training_dataset = SampledImageFolder(image_datasets['training'], sampled_training_indices)\n","sampled_validation_dataset = SampledImageFolder(image_datasets['validation'], sampled_validation_indices)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### collate function for data per batch"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T11:00:54.174698Z","iopub.status.busy":"2024-10-23T11:00:54.173829Z","iopub.status.idle":"2024-10-23T11:00:54.179646Z","shell.execute_reply":"2024-10-23T11:00:54.178602Z","shell.execute_reply.started":"2024-10-23T11:00:54.174654Z"},"trusted":true},"outputs":[],"source":["\n","def collate_fn(batch):\n","    data = {}\n","    data[\"pixel_values\"] = torch.stack([x[0] for x in batch])\n","    data[\"labels\"] = torch.tensor([x[1] for x in batch])\n","\n","    return data"]},{"cell_type":"markdown","metadata":{},"source":["### metrics"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T11:00:55.469843Z","iopub.status.busy":"2024-10-23T11:00:55.468999Z","iopub.status.idle":"2024-10-23T11:01:00.888435Z","shell.execute_reply":"2024-10-23T11:01:00.887429Z","shell.execute_reply.started":"2024-10-23T11:00:55.469802Z"},"trusted":true},"outputs":[],"source":["accuracy = evaluate.load(\"accuracy\")\n","precision = evaluate.load(\"precision\")\n","recall = evaluate.load(\"recall\")\n","f1_score = evaluate.load(\"f1\")\n","balanced_accuracy = evaluate.load(\"hyperml/balanced_accuracy\")\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T11:01:09.854635Z","iopub.status.busy":"2024-10-23T11:01:09.853989Z","iopub.status.idle":"2024-10-23T11:01:09.862326Z","shell.execute_reply":"2024-10-23T11:01:09.861078Z","shell.execute_reply.started":"2024-10-23T11:01:09.854590Z"},"trusted":true},"outputs":[],"source":["def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","\n","    acc = accuracy.compute(predictions=predictions, references=labels)\n","    prn = precision.compute(predictions=predictions, references=labels, average=\"weighted\")\n","    rel = recall.compute(predictions=predictions, references=labels, average=\"weighted\")\n","    f1 = f1_score.compute(predictions=predictions, references=labels, average=\"weighted\")\n","    bal_acc = balanced_accuracy.compute(predictions=predictions, references=labels)\n","\n","    return {\"accuracy\" : acc[\"accuracy\"],\n","            \"precision\" : prn[\"precision\"],\n","            \"recall\" : rel[\"recall\"],\n","            \"f1\" : f1[\"f1\"],\n","            \"balanced_accuracy\": bal_acc.get(\"balanced_accuracy\", None)\n","            }\n"]},{"cell_type":"markdown","metadata":{},"source":["### model loading"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T11:01:12.879634Z","iopub.status.busy":"2024-10-23T11:01:12.879256Z","iopub.status.idle":"2024-10-23T11:01:16.923628Z","shell.execute_reply":"2024-10-23T11:01:16.922901Z","shell.execute_reply.started":"2024-10-23T11:01:12.879597Z"},"trusted":true},"outputs":[],"source":["\n","model = AutoModelForImageClassification.from_pretrained(\n","    checkpoint,\n","    num_labels=len(class_names),\n","    id2label=id2label,\n","    label2id=label2id,\n","    ignore_mismatched_sizes = True\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### training arguments"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T11:01:46.455538Z","iopub.status.busy":"2024-10-23T11:01:46.454584Z","iopub.status.idle":"2024-10-23T11:01:46.573323Z","shell.execute_reply":"2024-10-23T11:01:46.572530Z","shell.execute_reply.started":"2024-10-23T11:01:46.455483Z"},"trusted":true},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=\"SWIN_MEDICAL_6\",\n","    remove_unused_columns=False,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=1,\n","    per_device_eval_batch_size=4,\n","    num_train_epochs=30,\n","    warmup_ratio=0.1,\n","    greater_is_better=True,\n","    load_best_model_at_end=True,\n","    save_total_limit=2,\n","    metric_for_best_model=\"balanced_accuracy\",\n","    report_to=\"none\"\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["### setting up trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T11:01:47.759706Z","iopub.status.busy":"2024-10-23T11:01:47.759329Z","iopub.status.idle":"2024-10-23T11:01:48.082092Z","shell.execute_reply":"2024-10-23T11:01:48.081274Z","shell.execute_reply.started":"2024-10-23T11:01:47.759670Z"},"trusted":true},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=collate_fn,\n","\n","    train_dataset=sampled_validation_dataset,\n","    eval_dataset=sampled_validation_dataset,\n","    tokenizer=image_processor,\n","    compute_metrics=compute_metrics,\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["### model training and evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T11:01:49.014595Z","iopub.status.busy":"2024-10-23T11:01:49.014239Z"},"trusted":true},"outputs":[],"source":["\n","train_results = trainer.train()\n","\n","trainer.save_model()\n","trainer.log_metrics(\"train\", train_results.metrics)\n","trainer.save_metrics(\"train\", train_results.metrics)\n","trainer.save_state()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T02:27:47.780932Z","iopub.status.busy":"2024-10-23T02:27:47.780538Z","iopub.status.idle":"2024-10-23T02:29:17.609874Z","shell.execute_reply":"2024-10-23T02:29:17.608973Z","shell.execute_reply.started":"2024-10-23T02:27:47.780894Z"},"trusted":true},"outputs":[],"source":["metrics = trainer.evaluate()\n","\n","trainer.log_metrics(\"eval\", metrics)\n","trainer.save_metrics(\"eval\", metrics)"]},{"cell_type":"markdown","metadata":{},"source":["### zip the model folder and download "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-23T02:29:26.696905Z","iopub.status.busy":"2024-10-23T02:29:26.696270Z","iopub.status.idle":"2024-10-23T02:30:07.003600Z","shell.execute_reply":"2024-10-23T02:30:07.002487Z","shell.execute_reply.started":"2024-10-23T02:29:26.696865Z"},"trusted":true},"outputs":[],"source":["!zip -r \"/kaggle/working/SWIN_MEDICAL_6.zip\" \"/kaggle/working/SWIN_BASE_MEDICAL_6\""]},{"cell_type":"markdown","metadata":{},"source":["### Evaluation per class and mean AUC"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import AutoImageProcessor, AutoModelForImageClassification\n","import torch\n","import cv2\n","import os\n","import time\n","import numpy as np\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","from sklearn.preprocessing import label_binarize\n","\n","def swin_infer(image, model, device):\n","    with torch.no_grad():\n","        inputs = image_processor(image, return_tensors=\"pt\").to(device)\n","        logits = model(**inputs).logits\n","        probabilities = torch.softmax(logits, dim=-1).cpu().numpy()\n","        predicted_label = logits.argmax(-1).item()\n","        label = model.config.id2label[predicted_label]\n","        if probabilities.ndim == 1:\n","            probabilities = probabilities.reshape(1, -1)\n","        return label, probabilities\n","\n","def evaluate_classification(actual_dict, predicted_dict, class_names, predicted_probs):\n","    y_true = []\n","    y_pred = []\n","    for cls in class_names:\n","        y_true.extend([cls] * actual_dict.get(cls, 0))\n","        y_pred.extend([cls] * predicted_dict.get(cls, 0))\n","\n","    class_to_index = {cls: idx for idx, cls in enumerate(class_names)}\n","    y_true = np.array([class_to_index[label] for label in y_true])\n","    y_pred = np.array([class_to_index[label] for label in y_pred])\n","    \n","    # Compute confusion matrix and other metrics\n","    conf_matrix = confusion_matrix(y_true, y_pred, labels=list(class_to_index.values()))\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n","    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n","    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n","\n","    return conf_matrix, accuracy, precision, recall, f1\n","\n","# Class names and folder structure\n","class_names = ['Angioectasia', 'Bleeding', 'Erosion', 'Erythema', 'Foreign Body', 'Lymphangiectasia', 'Normal', 'Polyp', 'Ulcer', 'Worms']\n","sub_folders = [\"KID\", \"KVASIR\", \"SEE-AI\", \"AIIMS\"]\n","val_folder = \"/kaggle/input/misahub-capsule-vision-training-challenge-2024/Dataset/validation\"\n","\n","# Device setup\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","image_processor = AutoImageProcessor.from_pretrained(\"/kaggle/working/SWIN_MEDICAL_6\")\n","model = AutoModelForImageClassification.from_pretrained(\"/kaggle/working/SWIN_MEDICAL_6\")\n","model.to(device)\n","\n","# Timing and results storage\n","time_for_all_image = []\n","final_confusion_matrix = np.zeros((len(class_names), len(class_names)), dtype=int)\n","all_predicted_probs = []\n","all_true_labels = []\n","\n","# Evaluation loop\n","for cls in class_names:\n","    total_samples_classes = {cls: 0}\n","    pred_samples_classes = {cls: 0}\n","    for fldr in sub_folders:\n","        orig_classes = {cls: 0 for cls in class_names}\n","        classes = {cls: 0 for cls in class_names}\n","        folder = os.path.join(val_folder, cls, fldr)\n","        if os.path.exists(folder):\n","            images = os.listdir(folder)\n","            orig_classes[cls] += len(images)\n","            total_samples_classes[cls] += len(images)\n","            for name in images:\n","                start = time.process_time()\n","                path = os.path.join(folder, name)\n","                image = cv2.imread(path)\n","                lbl, probabilities = swin_infer(image, model, device)\n","                all_predicted_probs.append(probabilities)\n","                all_true_labels.append(class_names.index(cls))  # Store the true class index\n","                if lbl not in classes:\n","                    classes[lbl] = 0\n","                if lbl not in pred_samples_classes:\n","                    pred_samples_classes[lbl] = 0\n","                classes[lbl] += 1\n","                pred_samples_classes[lbl] += 1\n","                end = time.process_time()\n","                infer_time = end - start\n","                time_for_all_image.append(infer_time)\n","\n","            print(f\"Result per class ----- {cls} subfolder ------- {fldr}\")\n","            print(\"Actual    ------\", orig_classes)\n","            print(\"Predicted ------\", classes)\n","            print(f\"Total samples = {orig_classes[cls]} Predicted Samples = {classes[cls]}\")\n","            conf_matrix, accuracy, precision, recall, f1 = evaluate_classification(\n","                orig_classes,\n","                classes,\n","                class_names,\n","                np.vstack(all_predicted_probs) if all_predicted_probs else np.empty((0, len(class_names)))\n","            )\n","            print(\"Confusion Matrix:\")\n","            print(conf_matrix)\n","            print(f\"Accuracy: {accuracy:.4f}\")\n","            print(f\"Precision: {precision:.4f}\")\n","            print(f\"Recall: {recall:.4f}\")\n","            print(f\"F1 Score: {f1:.4f}\")\n","            final_confusion_matrix += conf_matrix\n","\n","# Calculate Mean AUC only once at the end\n","y_true_bin = label_binarize(all_true_labels, classes=range(len(class_names)))\n","all_predicted_probs = np.vstack(all_predicted_probs)  # Convert list to array\n","\n","mean_auc = 0\n","valid_classes = 0\n","for i in range(len(class_names)):\n","    if np.sum(y_true_bin[:, i]) > 0 and np.sum(1 - y_true_bin[:, i]) > 0:  # Ensure both positive and negative samples exist\n","        mean_auc += roc_auc_score(y_true_bin[:, i], all_predicted_probs[:, i])\n","        valid_classes += 1\n","\n","if valid_classes > 0:\n","    mean_auc /= valid_classes  # Average AUC across valid classes\n","else:\n","    print(\"No valid classes for AUC calculation.\")\n","\n","# Final results\n","print(\" --------------------- Full Result --------------------- \")\n","print(\"Total Confusion Matrix:\")\n","print(final_confusion_matrix)\n","print(\"Total images:\", len(time_for_all_image))\n","print(\"Total time taken:\", sum(time_for_all_image))\n","print(\"Time taken per image:\", sum(time_for_all_image) / len(time_for_all_image))\n","print(f\"Final Mean AUC: {mean_auc:.4f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Retraining on Validation data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","checkpoint = \"SWIN_MEDICAL_6/kaggle/working/SWIN_MEDICAL_6\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_processor = AutoImageProcessor.from_pretrained(checkpoint, use_fast=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","model = AutoModelForImageClassification.from_pretrained(\n","    checkpoint,\n","    num_labels=len(class_names),\n","    id2label=id2label,\n","    label2id=label2id,\n","    ignore_mismatched_sizes = True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=\"/kaggle/working/SWIN_MEDICAL_6_validation\",\n","    remove_unused_columns=False,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=1,\n","    per_device_eval_batch_size=4,\n","    num_train_epochs=20,\n","    warmup_ratio=0.1,\n","    greater_is_better=True,\n","    load_best_model_at_end=True,\n","    save_total_limit=2,\n","    # metric_for_best_model=\"accuracy\",\n","    metric_for_best_model=\"balanced_accuracy\",\n","    report_to=\"none\"\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=collate_fn,\n","    train_dataset=sampled_validation_dataset,\n","    eval_dataset=sampled_validation_dataset,\n","    tokenizer=image_processor,\n","    compute_metrics=compute_metrics,\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","train_results = trainer.train()\n","\n","trainer.save_model()\n","trainer.log_metrics(\"train\", train_results.metrics)\n","trainer.save_metrics(\"train\", train_results.metrics)\n","trainer.save_state()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["metrics = trainer.evaluate()\n","\n","trainer.log_metrics(\"eval\", metrics)\n","trainer.save_metrics(\"eval\", metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!zip -r \"/kaggle/working/SWIN_MEDICAL_6_validation.zip\" \"/kaggle/working/SWIN_MEDICAL_6_validation\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import AutoImageProcessor, AutoModelForImageClassification\n","import torch\n","import cv2\n","import os\n","import time\n","import numpy as np\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","from sklearn.preprocessing import label_binarize\n","\n","def swin_infer(image, model, device):\n","    with torch.no_grad():\n","        inputs = image_processor(image, return_tensors=\"pt\").to(device)\n","        logits = model(**inputs).logits\n","        probabilities = torch.softmax(logits, dim=-1).cpu().numpy()\n","        predicted_label = logits.argmax(-1).item()\n","        label = model.config.id2label[predicted_label]\n","        if probabilities.ndim == 1:\n","            probabilities = probabilities.reshape(1, -1)\n","        return label, probabilities\n","\n","def evaluate_classification(actual_dict, predicted_dict, class_names, predicted_probs):\n","    y_true = []\n","    y_pred = []\n","    for cls in class_names:\n","        y_true.extend([cls] * actual_dict.get(cls, 0))\n","        y_pred.extend([cls] * predicted_dict.get(cls, 0))\n","\n","    class_to_index = {cls: idx for idx, cls in enumerate(class_names)}\n","    y_true = np.array([class_to_index[label] for label in y_true])\n","    y_pred = np.array([class_to_index[label] for label in y_pred])\n","    \n","    # Compute confusion matrix and other metrics\n","    conf_matrix = confusion_matrix(y_true, y_pred, labels=list(class_to_index.values()))\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n","    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n","    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n","\n","    return conf_matrix, accuracy, precision, recall, f1\n","\n","# Class names and folder structure\n","class_names = ['Angioectasia', 'Bleeding', 'Erosion', 'Erythema', 'Foreign Body', 'Lymphangiectasia', 'Normal', 'Polyp', 'Ulcer', 'Worms']\n","sub_folders = [\"KID\", \"KVASIR\", \"SEE-AI\", \"AIIMS\"]\n","val_folder = \"/kaggle/input/misahub-capsule-vision-training-challenge-2024/Dataset/validation\"\n","\n","# Device setup\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","image_processor = AutoImageProcessor.from_pretrained(\"/kaggle/working/SWIN_MEDICAL_6_validation\")\n","model = AutoModelForImageClassification.from_pretrained(\"/kaggle/working/SWIN_MEDICAL_6_validation\")\n","model.to(device)\n","\n","# Timing and results storage\n","time_for_all_image = []\n","final_confusion_matrix = np.zeros((len(class_names), len(class_names)), dtype=int)\n","all_predicted_probs = []\n","all_true_labels = []\n","\n","# Evaluation loop\n","for cls in class_names:\n","    total_samples_classes = {cls: 0}\n","    pred_samples_classes = {cls: 0}\n","    for fldr in sub_folders:\n","        orig_classes = {cls: 0 for cls in class_names}\n","        classes = {cls: 0 for cls in class_names}\n","        folder = os.path.join(val_folder, cls, fldr)\n","        if os.path.exists(folder):\n","            images = os.listdir(folder)\n","            orig_classes[cls] += len(images)\n","            total_samples_classes[cls] += len(images)\n","            for name in images:\n","                start = time.process_time()\n","                path = os.path.join(folder, name)\n","                image = cv2.imread(path)\n","                lbl, probabilities = swin_infer(image, model, device)\n","                all_predicted_probs.append(probabilities)\n","                all_true_labels.append(class_names.index(cls))  # Store the true class index\n","                if lbl not in classes:\n","                    classes[lbl] = 0\n","                if lbl not in pred_samples_classes:\n","                    pred_samples_classes[lbl] = 0\n","                classes[lbl] += 1\n","                pred_samples_classes[lbl] += 1\n","                end = time.process_time()\n","                infer_time = end - start\n","                time_for_all_image.append(infer_time)\n","\n","            print(f\"Result per class ----- {cls} subfolder ------- {fldr}\")\n","            print(\"Actual    ------\", orig_classes)\n","            print(\"Predicted ------\", classes)\n","            print(f\"Total samples = {orig_classes[cls]} Predicted Samples = {classes[cls]}\")\n","            conf_matrix, accuracy, precision, recall, f1 = evaluate_classification(\n","                orig_classes,\n","                classes,\n","                class_names,\n","                np.vstack(all_predicted_probs) if all_predicted_probs else np.empty((0, len(class_names)))\n","            )\n","            print(\"Confusion Matrix:\")\n","            print(conf_matrix)\n","            print(f\"Accuracy: {accuracy:.4f}\")\n","            print(f\"Precision: {precision:.4f}\")\n","            print(f\"Recall: {recall:.4f}\")\n","            print(f\"F1 Score: {f1:.4f}\")\n","            final_confusion_matrix += conf_matrix\n","\n","# Calculate Mean AUC only once at the end\n","y_true_bin = label_binarize(all_true_labels, classes=range(len(class_names)))\n","all_predicted_probs = np.vstack(all_predicted_probs)  # Convert list to array\n","\n","mean_auc = 0\n","valid_classes = 0\n","for i in range(len(class_names)):\n","    if np.sum(y_true_bin[:, i]) > 0 and np.sum(1 - y_true_bin[:, i]) > 0:  # Ensure both positive and negative samples exist\n","        mean_auc += roc_auc_score(y_true_bin[:, i], all_predicted_probs[:, i])\n","        valid_classes += 1\n","\n","if valid_classes > 0:\n","    mean_auc /= valid_classes  # Average AUC across valid classes\n","else:\n","    print(\"No valid classes for AUC calculation.\")\n","\n","# Final results\n","print(\" --------------------- Full Result --------------------- \")\n","print(\"Total Confusion Matrix:\")\n","print(final_confusion_matrix)\n","print(\"Total images:\", len(time_for_all_image))\n","print(\"Total time taken:\", sum(time_for_all_image))\n","print(\"Time taken per image:\", sum(time_for_all_image) / len(time_for_all_image))\n","print(f\"Final Mean AUC: {mean_auc:.4f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Final Output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import AutoImageProcessor, AutoModelForImageClassification\n","import torch\n","import cv2 \n","import os\n","import numpy as np\n","import pandas as pd\n","\n","def swin_infer(image, model, device):\n","    with torch.no_grad():\n","        inputs = image_processor(image, return_tensors=\"pt\").to(device)\n","        logits = model(**inputs).logits\n","        probabilities = torch.softmax(logits, dim=-1)  # Apply softmax to logits\n","        predicted_label = probabilities.argmax(-1).item()\n","        label = model.config.id2label[predicted_label]\n","    return label, probabilities\n","\n","class_names = ['Angioectasia', 'Bleeding', 'Erosion', 'Erythema', \n","               'Foreign Body', 'Lymphangiectasia', 'Normal', 'Polyp', \n","               'Ulcer', 'Worms']\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","image_processor = AutoImageProcessor.from_pretrained(\"/kaggle/working/SWIN_MEDICAL_6_validation\")\n","model = AutoModelForImageClassification.from_pretrained(\"/kaggle/working/SWIN_MEDICAL_6_validation\")\n","model.to(device)\n","\n","folder = \"/kaggle/input/misahub-capsule-vision-challenge-2024/Testing set/Images\"\n","images = os.listdir(folder)\n","\n","# Prepare lists to collect results\n","logits_results = []\n","\n","for image_name in images:\n","    image_path = os.path.join(folder, image_name)\n","    \n","    image = cv2.imread(image_path)\n","\n","    if image is not None:\n","        label, probabilities = swin_infer(image, model, device)\n","        probabilities = probabilities.cpu().numpy().flatten()  # Flatten the probabilities\n","\n","        # Logits data\n","        logits_results.append([image_name] + probabilities.tolist() + [label])\n","        \n","    else:\n","        print(f\"Failed to load image: {image_path}\")\n","\n","# Create DataFrame\n","logits_df = pd.DataFrame(logits_results, columns=['image_path'] + class_names + ['predicted_class'])\n","\n","# Save DataFrame to Excel\n","logits_output_file = \"/kaggle/working/SWIN_MEDICAL_6_validation_trained_output.xlsx\"\n","logits_df.to_excel(logits_output_file, index=False)\n","\n","print(f\"Logits saved to {logits_output_file}\")\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5919926,"sourceId":9684442,"sourceType":"datasetVersion"},{"datasetId":5925619,"sourceId":9692190,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
